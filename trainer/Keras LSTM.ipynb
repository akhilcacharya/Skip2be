{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU, ConvLSTM2D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_path = \"../data/fasttext/dataset.train\"\n",
    "validation_path = \"../data/fasttext/dataset.valid\"\n",
    "test_path = \"../data/fasttext/dataset.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 8\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n",
      "Loaded embeddings\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading embeddings...\")\n",
    "vectorizer = load_embeddings()\n",
    "print(\"Loaded embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embeddings(): \n",
    "    vectorizer = KeyedVectors.load_word2vec_format('crawl-300d-2M.vec')\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_to(input_list, max_len): \n",
    "    unk = np.zeros(300)\n",
    "    if len(input_list) < max_len: \n",
    "        diff = max_len - len(input_list)\n",
    "        input_list = input_list + ([unk] * diff)\n",
    "    else: \n",
    "        input_list = input_list[:max_len]\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(vectorizer, path): \n",
    "    print(\"Loading\", path)\n",
    "    # List of list of vectors\n",
    "    # Final dimension = # samples, max_len, vector_length\n",
    "    X = [] \n",
    "    Y = [] \n",
    "    with open(path, \"r\") as data_file: \n",
    "        for line in data_file.readlines(): \n",
    "            comps = line.split(\" \")\n",
    "        \n",
    "            if \"0\" in comps[0]: \n",
    "                label = 0 \n",
    "            else: \n",
    "                label = 1\n",
    "\n",
    "            Y.append(label)\n",
    "\n",
    "            comps = comps[1:]\n",
    "            sentence = []\n",
    "            for token in comps: \n",
    "                try: \n",
    "                    sentence.append(vectorizer.get_vector(token))\n",
    "                except: \n",
    "                    pass\n",
    "            sentence = pad_to(sentence, max_len)\n",
    "            X.append(sentence)\n",
    "\n",
    "    return np.asarray(X), np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(): \n",
    "    print('Loading data...')\n",
    "\n",
    "    x_train, y_train = load_data(vectorizer, training_path)\n",
    "    x_valid, y_valid = load_data(vectorizer, validation_path)\n",
    "    x_test, y_test = load_data(vectorizer, test_path)\n",
    "\n",
    "    print(len(x_train), 'train sequences')\n",
    "    print(len(x_test), 'test sequences')\n",
    "\n",
    "    print('x_train shape:', x_train.shape, y_train.shape)\n",
    "    print('x_test shape:', x_test.shape, y_test.shape)\n",
    "\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.4), input_shape=(8, 300)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=15,\n",
    "            validation_data=(x_test, y_test))\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    predicted = model.predict(x_test)\n",
    "    predicted_bin = [round(pred[0]) for pred in predicted]\n",
    "    report = classification_report(y_test, predicted_bin)\n",
    "    print(report)\n",
    "        \n",
    "    model.save(\"bidirectional_keras_lstm.h5\")\n",
    "    \n",
    "    print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading ../data/fasttext/dataset.train\n",
      "Loading ../data/fasttext/dataset.valid\n",
      "Loading ../data/fasttext/dataset.test\n",
      "4010 train sequences\n",
      "859 test sequences\n",
      "x_train shape: (4010, 8, 300) (4010,)\n",
      "x_test shape: (859, 8, 300) (859,)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 4010 samples, validate on 859 samples\n",
      "Epoch 1/15\n",
      "4010/4010 [==============================] - 7s 2ms/step - loss: 0.3591 - acc: 0.8753 - val_loss: 0.2948 - val_acc: 0.8964\n",
      "Epoch 2/15\n",
      "4010/4010 [==============================] - 2s 459us/step - loss: 0.2623 - acc: 0.8965 - val_loss: 0.2889 - val_acc: 0.9080\n",
      "Epoch 3/15\n",
      "4010/4010 [==============================] - 2s 434us/step - loss: 0.2352 - acc: 0.9065 - val_loss: 0.2772 - val_acc: 0.9034\n",
      "Epoch 4/15\n",
      "4010/4010 [==============================] - 2s 425us/step - loss: 0.2068 - acc: 0.9175 - val_loss: 0.3056 - val_acc: 0.8847\n",
      "Epoch 5/15\n",
      "4010/4010 [==============================] - 2s 432us/step - loss: 0.1954 - acc: 0.9207 - val_loss: 0.3204 - val_acc: 0.8789\n",
      "Epoch 6/15\n",
      "4010/4010 [==============================] - 2s 447us/step - loss: 0.1833 - acc: 0.9234 - val_loss: 0.3073 - val_acc: 0.8906\n",
      "Epoch 7/15\n",
      "4010/4010 [==============================] - 2s 419us/step - loss: 0.1679 - acc: 0.9339 - val_loss: 0.3277 - val_acc: 0.8952\n",
      "Epoch 8/15\n",
      "4010/4010 [==============================] - 2s 420us/step - loss: 0.1555 - acc: 0.9372 - val_loss: 0.3465 - val_acc: 0.8941\n",
      "Epoch 9/15\n",
      "4010/4010 [==============================] - 2s 431us/step - loss: 0.1502 - acc: 0.9426 - val_loss: 0.3489 - val_acc: 0.8929\n",
      "Epoch 10/15\n",
      "4010/4010 [==============================] - 2s 436us/step - loss: 0.1417 - acc: 0.9429 - val_loss: 0.3547 - val_acc: 0.8708\n",
      "Epoch 11/15\n",
      "4010/4010 [==============================] - 2s 448us/step - loss: 0.1288 - acc: 0.9449 - val_loss: 0.3569 - val_acc: 0.8906\n",
      "Epoch 12/15\n",
      "4010/4010 [==============================] - 2s 435us/step - loss: 0.1180 - acc: 0.9514 - val_loss: 0.3457 - val_acc: 0.8906\n",
      "Epoch 13/15\n",
      "4010/4010 [==============================] - 2s 420us/step - loss: 0.1080 - acc: 0.9554 - val_loss: 0.4047 - val_acc: 0.8638\n",
      "Epoch 14/15\n",
      "4010/4010 [==============================] - 2s 420us/step - loss: 0.0999 - acc: 0.9608 - val_loss: 0.3922 - val_acc: 0.8789\n",
      "Epoch 15/15\n",
      "4010/4010 [==============================] - 2s 441us/step - loss: 0.0853 - acc: 0.9653 - val_loss: 0.4098 - val_acc: 0.8638\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.91      0.92       764\n",
      "          1       0.41      0.51      0.45        95\n",
      "\n",
      "avg / total       0.88      0.86      0.87       859\n",
      "\n",
      "[[694  70]\n",
      " [ 47  48]]\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
